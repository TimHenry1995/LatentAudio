{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s17TFw2ZKSlb"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df9XjKHbmMqg"
      },
      "source": [
        "Pre-processing is performed mostly by configuring and running existing scripts as shown below. There are two kinds of analysis performed in Processing.ipynb that need to be prepared here, namely latent space exploration and manipulation. \n",
        "Latent space exploration involves \n",
        "- projection with principal component analysis (PCA),\n",
        "- t-distributed stochastic neighbor embeddings (t-SNE),\n",
        "- classification of latent representations as materials and actions using k-nearest neighbors (KNN) and \n",
        "- disententanglement with a flow model.\n",
        "\n",
        "Latent space manipulation involves\n",
        "- invertible projection with PCA. This requires a complete PCA model whose output and input dimensionality is the same which is processing intensive to set up.\n",
        "- disentanglement with a flow model. This flow model needs to be invertible. The one listed for exploration will work as it is.\n",
        "\n",
        "The preparation for these two analyses is similar in many ways. They both require the conversion of data from its waveform domain to Yament's latent representation for each layer and the projection to manageable dimensionality, e.g. 64 dimensions using PCA. Note that computing a full PCA model is resource intensive and a small model with e.g. 64 dimensions will suffice for most layers. For the majority of layers, the original latent space representations that are of higher dimensionality than the projection are also no longer needed after projection. Only the layers whose latent space shall be manipulated need the full PCA model for invertability and need the original latent space representation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ_WX9hPq8q9"
      },
      "source": [
        "The pre-processing can thus be prepared as follows: For each layer l of Yamnet:\n",
        "  - Convert all sounds to their latent representation at layer l.\n",
        "  - Fit standard scalers and PCA to a sample of these representations. Since the dimensionality of the first 3 Yamnet layers is too large, a complete PCA model cannot be created for them. Yet, for these layers, a PCA model that only creates the first few dimensions is sufficient to explore the latent space in subsequent experiments. Only for the layers whose original dimensionality is sufficiently small, it will be possible to create a PCA model with as many output dimensions as input dimensions. Depending on system resources, this might work for layers 4 and 5. It should work for layers 6 and onwards for every reasonably equipped machine.  \n",
        "  - Using the previously created PCA model, project the latent Yamnet representations of sounds to a more manageable dimensionality.\n",
        "  - Optionally delete the higher dimensional representations. The  experiment of the accompanying paper only does keeps the high dimensional representations for layer 9. As a consequence, the final disk storage will be minimized.\n",
        "  \n",
        "Important: These steps require several hours to be executed and memory as well as disk storage demands can temporarily peak."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qnjNPyAf7OK",
        "outputId": "489189f1-9ee4-4b75-c27c-33591f460d78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 13\n",
            "Running script to convert audio to latent yamnet\n",
            "\t100.0% Completed\n",
            "\tRun Completed\n",
            "Running script to create scalers and PCA model for latent yamnet\n",
            "\tLoading sample of latent data Completed. Shape == [instance count, dimensionality] == (10000, 6144)\n",
            "\tFitting Pre-PCA Standard Scaler to sample Completed\n",
            "\tFitting 64-dimensional PCA to sample Completed\n",
            "\tFitting Post-PCA Standard Scaler to sample Completed\n",
            "\tRun Completed\n",
            "Running script to convert latent yamnet to calibration data set\n",
            "\tThe top 64 dimensions explain 83.16 % of variance.\n",
            "\t100.0 % Completed\n",
            "\tRun completed\n"
          ]
        }
      ],
      "source": [
        "from latent_audio.scripts import audio_to_latent_yamnet as aud2lat, create_scalers_and_PCA_model_for_latent_yamnet as lat2pca, latent_yamnet_to_calibration_data_set as lat2cal\n",
        "import shutil, os\n",
        "\n",
        "full_dim_layer_indices = [9]\n",
        "reduced_target_dimensionality = 64\n",
        "\n",
        "for layer_index in range(14):\n",
        "    print(f'Layer {layer_index}')\n",
        "    # Extract data\n",
        "    aud2lat.run(layer_index=layer_index) # Converts audio to latent yamnet representation of original dimensionality\n",
        "    lat2pca.run(layer_index=layer_index, target_dimensionality=None if layer_index in full_dim_layer_indices else reduced_target_dimensionality) # Creates standard scalers and PCA for projection to lower dimensional space\n",
        "    lat2cal.run(layer_index=layer_index, dimensionality=reduced_target_dimensionality) # Performs the projection (this will be needed for all layers)\n",
        "\n",
        "    # Delete latent representations of original dimensionality to save disk storage\n",
        "    if layer_index not in full_dim_layer_indices:\n",
        "        shutil.rmtree(os.path.join(\"data\",\"latent yamnet\",\"original\",f\"Layer {layer_index}\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
