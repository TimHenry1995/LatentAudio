{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sKruXK9KKkP"
      },
      "source": [
        "#Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shbboBpulZZ7"
      },
      "source": [
        "The installation involves downloading the LatentAudio github repository and installing its dependencies. Important: The dependency tensorflow has to be installed as version 2.9. This version appears to be available only for x86 systems, not for arm. If you do not manage to install this tensorflow version on your local machine, try running it in Google Colab. After the installation it might be necessary to restart the runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa72dvbnHsBm"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/TimHenry1995/LatentAudio.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rSQFBcgHvyg"
      },
      "outputs": [],
      "source": [
        "%cd LatentAudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDSR34AZIAbC"
      },
      "outputs": [],
      "source": [
        "%pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After installation, restart the kernel of the notebook. Then continue from here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEHaABRaWQNV",
        "outputId": "aeb6a416-fc72-427b-c094-ee9af9c63acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/LatentAudio\n"
          ]
        }
      ],
      "source": [
        "%cd LatentAudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s17TFw2ZKSlb"
      },
      "source": [
        "#Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df9XjKHbmMqg"
      },
      "source": [
        "Processing is performed mostly by configuring and running existing scripts as shown below. There are two kinds of analysis that need to be prepared, namely latent space exploration and manipulation. \n",
        "Latent space exploration involves \n",
        "- projection with principal component analysis (PCA),\n",
        "- t-distributed stochastic neighbor embeddings (t-SNE),\n",
        "- classification of latent representations as materials and actions using k-nearest neighbors (KNN) and \n",
        "- disententanglement with a flow model.\n",
        "\n",
        "Latent space manipulation involves\n",
        "- invertible projection with PCA. This requires a complete PCA model whose output and input dimensionality is the same which is processing intensive to set up.\n",
        "- disentanglement with a flow model. This flow model needs to be invertible. The one listed for exploration will work as it is.\n",
        "\n",
        "The preparation for these two analyses is similar in many ways. They both require the conversion of data from its waveform domain to Yament's latent representation for each layer and the projection to manageable dimensionality, e.g. 64 dimensions using PCA. Since computing a full PCA model is resoruce intensive and a small model with e.g. 64 dimensions will suffice for most layers. The original latent space representations that are of higher dimensionality than the projection are also no longer needed after projection. Hence, they can be deleted. Only the layers whose latent space shall be manipulated need the full PCA model for invertability and need the original latent space representation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ_WX9hPq8q9"
      },
      "source": [
        "2. For each layer l of Yamnet, the following steps need to be executed\n",
        "  - Convert all sounds to their latent representation at layer l\n",
        "  - Fit standard scalers and PCA to a sample of these representations. Since the dimensionality of the early Yamnet layers is too large, a complete PCA model cannot be created for them. Yet, a PCA model that only creates the first few dimensions is sufficient to explore the latent space in subsequent experiments. Only for the layers whose original dimensionlaity is sufficiently small, it will be possible to create a PCA model with as many output dimensions as input dimensions. Depending on system resources, this migh twork for layers 4 and 5. It should work for layers 6 and onwards for every reasonably equipped machine.  \n",
        "  - Project the representations to a more manageable dimensionality\n",
        "  - Optionally delete the higher dimensional representations. The high dimensional representations are only needed for those layers for which downstream Yamnet processing is intended. Since the original experiment only does this for layer 9, it is not necessary to save these large representations for the remaining layers. As a cosnequence, the final disk storage will be minimized.\n",
        "  \n",
        "Important: These steps require several hours to be executed and memory as well as disk storage demands can temporarily peak."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qnjNPyAf7OK",
        "outputId": "489189f1-9ee4-4b75-c27c-33591f460d78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 13\n",
            "Running script to convert audio to latent yamnet\n",
            "\t100.0% Completed\n",
            "\tRun Completed\n",
            "Running script to create scalers and PCA model for latent yamnet\n",
            "\tLoading sample of latent data Completed. Shape == [instance count, dimensionality] == (10000, 6144)\n",
            "\tFitting Pre-PCA Standard Scaler to sample Completed\n",
            "\tFitting 64-dimensional PCA to sample Completed\n",
            "\tFitting Post-PCA Standard Scaler to sample Completed\n",
            "\tRun Completed\n",
            "Running script to convert latent yamnet to calibration data set\n",
            "\tThe top 64 dimensions explain 83.16 % of variance.\n",
            "\t100.0 % Completed\n",
            "\tRun completed\n"
          ]
        }
      ],
      "source": [
        "from latent_audio.scripts import audio_to_latent_yamnet as aud2lat, create_scalers_and_PCA_model_for_latent_yamnet as lat2pca, latent_yamnet_to_calibration_data_set as lat2cal\n",
        "import shutil, os\n",
        "\n",
        "full_dim_layer_indices = [9]\n",
        "reduced_target_dimensionality = 64\n",
        "\n",
        "for layer_index in range(14):\n",
        "    print(f'Layer {layer_index}')\n",
        "    # Extract data\n",
        "    aud2lat.run(layer_index=layer_index) # Converts audio to latent yamnet representation of original dimensionality\n",
        "    lat2pca.run(layer_index=layer_index, target_dimensionality=None if layer_index in full_dim_layer_indices else reduced_target_dimensionality) # Creates standard scalers and PCA for projection to lower dimensional space\n",
        "    lat2cal.run(layer_index=layer_index, dimensionality=reduced_target_dimensionality) # Performs the projection (this will be needed for all layers)\n",
        "\n",
        "    # Delete latent representations of original dimensionality to save disk storage\n",
        "    if layer_index not in full_dim_layer_indices:\n",
        "        shutil.rmtree(os.path.join(\"data\",\"latent yamnet\",\"original\",f\"Layer {layer_index}\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
